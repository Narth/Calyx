## Station Calyx design philosophy (non-technical, 300-500 words)

Station Calyx is a safety-first governance shell around AI, not just a local model. Its job is to keep humans in charge, keep the system observable, and make every action traceable. Calyx treats human primacy as absolute: you can always override, and the system will never claim authority or divinity. Bounded autonomy means no silent expansion of capabilities?Safe Mode and Execution Gate default to deny-all. Traceable causality demands that every output can be reconstructed from its inputs and logged reasoning. No hidden channels: everything meaningful is logged and auditable; there are no backdoors. Contestability: every result is provisional, designed to be questioned and corrected. Observability: telemetry, reflections, and node outputs are append-only so you can see what happened and why.

Unlike ?just running an LLM locally,? Calyx adds governance doctrine, reflection schemas, and capability gating. It instruments how the model is used, not just what it says. This yields predictable behavior, audit trails, and a clear separation between human intent and machine assistance. Calyx is intended to be lightweight and single-node friendly: outcome density and resource governance push for excellence before scaling. Its rituals (Station Routine, governance_cli, node outputs) ensure every session is timeboxed, observable, and human-directed. The result is an advisory tool that elevates clarity and accountability instead of autonomy. Calyx is a governed assistant, not a free-running agent; it exists to give you trustworthy, contestable outputs and to avoid surprises.
